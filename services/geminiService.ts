
import { GoogleGenAI, Type, Chat } from "@google/genai";
import type { DebateResult, ChatMessage, CaseFile, PreliminaryVerdict, SuggestedParticipant, CaseParticipant, CrossExaminationQuestion, Case, TimelineEvent, UsageInfo } from '../types';

if (!process.env.API_KEY) {
    throw new Error("API_KEY environment variable not set");
}

const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

// Price per token: 30,000 UZS / 1,000,000 tokens = 0.03 UZS per token
const PRICE_PER_TOKEN = 0.03;

const calculateUsage = (totalTokens: number | undefined): UsageInfo => {
    const tokens = totalTokens || 0;
    return {
        totalTokens: tokens,
        cost: tokens * PRICE_PER_TOKEN
    };
};

const getSystemInstruction = (language: string, isInvestigation: boolean = false): string => {
    const base = `–°–ï–ù –é–ó–ë–ï–ö–ò–°–¢–û–ù –†–ï–°–ü–£–ë–õ–ò–ö–ê–°–ò “ö–û–ù–£–ù–ß–ò–õ–ò–ì–ò –ë–é–ô–ò–ß–ê –≠–ù–ì –ö–£–ß–õ–ò 5 –¢–ê –≠–ö–°–ü–ï–†–¢–î–ê–ù –ò–ë–û–†–ê–¢ "–ê–î–û–õ–ê–¢ AI" –ê–î–í–û–ö–ê–¢–õ–ê–† –ñ–ê–ú–û–ê–°–ò–°–ê–ù.
“ö–ê–¢–™–ò–ô –¢–ê–õ–ê–ë–õ–ê–†:
1. –ñ–ê–í–û–ë–õ–ê–†–ù–ò –§–ê“ö–ê–¢ –é–ó–ë–ï–ö –¢–ò–õ–ò–î–ê –í–ê –§–ê“ö–ê–¢ –ö–ò–†–ò–õ–õ –ê–õ–ò–§–ë–û–°–ò–î–ê –Å–ó.
2. “≤–ê–† –ë–ò–† “≤–£“ö–£“ö–ò–ô –§–ò–ö–†–ù–ò –é–ó–ë–ï–ö–ò–°–¢–û–ù –†–ï–°–ü–£–ë–õ–ò–ö–ê–°–ò –ö–û–î–ï–ö–°–õ–ê–†–ò –í–ê –ú–û–î–î–ê–õ–ê–†–ò –ë–ò–õ–ê–ù –ê–°–û–°–õ–ê.
3. –ú–ê–¢–ù–î–ê–ì–ò –ò–°–ú–õ–ê–† –í–ê –†–û–õ–õ–ê–†–ù–ò (–î–ê–™–í–û–ì–ê–†, –ñ–ê–í–û–ë–ì–ê–†) “≤–ï–ß “ö–ê–ß–û–ù –ê–î–ê–®–¢–ò–†–ú–ê.
4. –¢–ê“≤–õ–ò–õ –Æ–ó–ê–ö–ò –ë–é–õ–ú–ê–°–ò–ù, –ò–®–ù–ò–ù–ì –≠–ù–ì –ö–ò–ß–ò–ö –î–ï–¢–ê–õ–õ–ê–†–ò–ì–ê–ß–ê –ö–ò–†–ò–ë –ë–û–†.
5. –ñ–ê–í–û–ë –ò–ß–ò–î–ê –õ–û–¢–ò–ù –ê–õ–ò–§–ë–û–°–ò–ù–ò –ò–®–õ–ê–¢–ú–ê (“≤–ê–í–û–õ–ê–õ–ê–†–î–ê–ù –¢–ê–®“ö–ê–†–ò).`;

    if (isInvestigation) {
        return `${base}\n–°–ï–ù –¢–ï–†–ì–û–í –ë–û–°“ö–ò–ß–ò–î–ê–ì–ò –ò–®–õ–ê–† –ë–é–ô–ò–ß–ê –≠–ö–°–ü–ï–†–¢–°–ê–ù. –ñ–ê–í–û–ë–ì–ê–†–ù–ò–ù–ì “≤–£“ö–£“ö–õ–ê–†–ò –í–ê –ü–†–û–¶–ï–°–°–£–ê–õ –•–ê–¢–û–õ–ê–†–ì–ê –î–ò“ö“ö–ê–¢ “ö–ò–õ.`;
    }
    return base;
};

const parseGeminiError = (error: any): Error => {
    console.error("–ì–ï–ú–ò–ù–ò –•–ê–¢–û–õ–ò–ì–ò:", error);
    const message = error?.message || 'Unknown error';
    if (message.includes("INVALID_ARGUMENT")) return new Error("–§–∞–π–ª “≥–∞–∂–º–∏ –∂—É–¥–∞ –∫–∞—Ç—Ç–∞. –ò–ª—Ç–∏–º–æ—Å, —Ñ–∞–π–ª–ª–∞—Ä–Ω–∏ –∫–∏—á–∏—Ä–æ“õ “õ–∏–ª–∏–± —é–±–æ—Ä–∏–Ω–≥.");
    if (message.includes("[429]")) return new Error('error_api_rate_limit');
    return new Error('error_api_unknown');
};

const aggregateText = (caseDetails: string, files: CaseFile[] | undefined, limit: number = 60000): string => {
    let combined = `–ò–® –¢–ê–§–°–ò–õ–û–¢–õ–ê–†–ò:\n${caseDetails}\n\n`;
    (files || []).forEach(f => {
        if (f.extractedText) {
            combined += `--- “≤–£–ñ–ñ–ê–¢ –ú–ê–ó–ú–£–ù–ò (${f.name}) ---
${f.extractedText}
--- “≤–£–ñ–ñ–ê–¢ –¢–£–ì–ê–î–ò ---

`;
        }
    });
    return combined.length > limit ? combined.substring(0, limit) : combined;
};

const participantsSchema = {
    type: Type.OBJECT,
    properties: {
        participants: {
            type: Type.ARRAY,
            items: {
                type: Type.OBJECT,
                properties: {
                    name: { type: Type.STRING, description: "–®–∞—Ö—Å–Ω–∏–Ω–≥ —Ç—û–ª–∏“õ –∏—Å–º–∏" },
                    suggestedRole: {
                        type: Type.STRING,
                        description: "–†–æ–ª–∏ (–î–∞—ä–≤–æ–≥–∞—Ä, –ñ–∞–≤–æ–±–≥–∞—Ä, –°—É–¥–ª–∞–Ω—É–≤—á–∏, –ñ–∞–±—Ä–ª–∞–Ω—É–≤—á–∏, –ì—É–≤–æ“≥, –°—É–¥—å—è, –ë–æ—à“õ–∞)"
                    }
                },
                required: ["name", "suggestedRole"]
            }
        }
    },
    required: ["participants"]
};

export const getCaseParticipants = async (caseDetails: string, files: CaseFile[], t: any, language: string): Promise<{ participants: SuggestedParticipant[], usage: UsageInfo }> => {
    try {
        const fullText = aggregateText(caseDetails, files, 40000);
        const fileParts = files
            .filter(f => f.content && (f.type === 'application/pdf' || f.type.startsWith('image/')))
            .slice(0, 3)
            .map(file => {
                const [, base64Data] = file.content!.split(',');
                return { inlineData: { mimeType: file.type, data: base64Data } };
            });

        const prompt = `–£—à–±—É “≥—É–∂–∂–∞—Ç –≤–∞ –º–∞—Ç–Ω–ª–∞—Ä–¥–∞–Ω –∏—à—Ç–∏—Ä–æ–∫—á–∏–ª–∞—Ä–Ω–∏ –≤–∞ —É–ª–∞—Ä–Ω–∏–Ω–≥ —Ä–æ–ª–ª–∞—Ä–∏–Ω–∏ –∞–Ω–∏“õ–ª–∞. –ú–ê–¢–ù: ${fullText}`;

        const response = await ai.models.generateContent({
            model: 'gemini-3-flash-preview',
            contents: { parts: [{ text: prompt }, ...fileParts] },
            config: {
                systemInstruction: getSystemInstruction(language),
                responseMimeType: "application/json",
                responseSchema: participantsSchema,
                temperature: 0.1
            },
        });

        const result = JSON.parse(response.text.trim());
        return {
            participants: result.participants || [],
            usage: calculateUsage(response.usageMetadata?.totalTokenCount)
        };
    } catch (error) {
        throw parseGeminiError(error);
    }
};

const legalStrategySchema = {
    type: Type.OBJECT,
    properties: {
        debate: {
            type: Type.ARRAY,
            items: {
                type: Type.OBJECT,
                properties: {
                    lawyerName: { type: Type.STRING },
                    analysis: { type: Type.STRING }
                },
                required: ["lawyerName", "analysis"]
            }
        },
        summary: { type: Type.STRING },
        winProbability: { type: Type.INTEGER },
        probabilityJustification: { type: Type.STRING },
        positiveFactors: { type: Type.ARRAY, items: { type: Type.STRING } },
        negativeFactors: { type: Type.ARRAY, items: { type: Type.STRING } },
        riskMatrix: {
            type: Type.ARRAY,
            items: {
                type: Type.OBJECT,
                properties: {
                    risk: { type: Type.STRING },
                    likelihood: { type: Type.STRING, enum: ['–ü–∞—Å—Ç', '–é—Ä—Ç–∞', '–Æ“õ–æ—Ä–∏'] },
                    mitigation: { type: Type.STRING }
                },
                required: ["risk", "likelihood", "mitigation"]
            }
        },
        suggestedTasks: { type: Type.ARRAY, items: { type: Type.STRING } },
        knowledgeBase: {
            type: Type.OBJECT,
            properties: {
                keyFacts: { type: Type.ARRAY, items: { type: Type.OBJECT, properties: { fact: { type: Type.STRING }, relevance: { type: Type.STRING } }, required: ["fact", "relevance"] } },
                legalIssues: { type: Type.ARRAY, items: { type: Type.STRING } },
                applicableLaws: { type: Type.ARRAY, items: { type: Type.OBJECT, properties: { article: { type: Type.STRING }, summary: { type: Type.STRING }, url: { type: Type.STRING }, relevance: { type: Type.STRING } }, required: ["article", "summary"] } },
                strengths: { type: Type.ARRAY, items: { type: Type.STRING } },
                weaknesses: { type: Type.ARRAY, items: { type: Type.STRING } },
                statuteOfLimitations: { type: Type.OBJECT, properties: { status: { type: Type.STRING, enum: ['OK', '–ú—É–¥–¥–∞—Ç–∏ —û—Ç–≥–∞–Ω', '–•–∞–≤—Ñ –æ—Å—Ç–∏–¥–∞'] }, summary: { type: Type.STRING } }, required: ["status", "summary"] }
            },
            required: ["keyFacts", "legalIssues", "applicableLaws", "strengths", "weaknesses", "statuteOfLimitations"]
        }
    },
    required: ["debate", "summary", "winProbability", "probabilityJustification", "knowledgeBase", "riskMatrix", "suggestedTasks"]
};

export const getLegalStrategy = async (caseDetails: string, files: CaseFile[], courtType: string, courtStage: string, clientRole: string, clientName: string, participants: CaseParticipant[], t: any, language: string): Promise<DebateResult & { usage: UsageInfo }> => {
    try {
        const isInvestigation = courtStage === 'Tergov_raw';
        const fullText = aggregateText(caseDetails, files, 60000);
        const participantsList = participants.map(p => `- ${p.name}: ${p.role}${p.name === clientName ? ' (–ú–ï–ù–ò–ù–ì –ú–ò–ñ–û–ó–ò–ú)' : ''}`).join('\n');

        const prompt = `–°–¢–†–ê–¢–ï–ì–ò–Ø –¢–£–ó–ò–ù–ì. –ú–ò–ñ–û–ó: ${clientName}. –ú–ê–¢–ù: ${fullText}. –ò–®–¢–ò–†–û–ö–ß–ò–õ–ê–†: ${participantsList}`;

        const response = await ai.models.generateContent({
            model: 'gemini-3-pro-preview',
            contents: { parts: [{ text: prompt }] },
            config: {
                systemInstruction: getSystemInstruction(language, isInvestigation),
                responseMimeType: "application/json",
                responseSchema: legalStrategySchema,
                temperature: 0.4,
                thinkingConfig: { thinkingBudget: 15000 }
            },
        });

        const parsed = JSON.parse(response.text.trim());
        const usage = calculateUsage(response.usageMetadata?.totalTokenCount);
        return { ...parsed, usage };
    } catch (error) { throw parseGeminiError(error); }
};

export const sendResearchMessage = async (message: string, t: any, language: string): Promise<ChatMessage> => {
    if (!researchChat) startResearchChat(t, language);
    const response = await researchChat!.sendMessage({ message });
    return {
        id: new Date().toISOString(),
        role: 'model',
        text: response.text,
        sources: response.candidates?.[0]?.groundingMetadata?.groundingChunks?.map(c => (c as any).web).filter(w => !!w?.uri) as any || [],
        usage: calculateUsage(response.usageMetadata?.totalTokenCount)
    };
};

let researchChat: Chat | null = null;
export const startResearchChat = (t: any, language: string) => {
    researchChat = ai.chats.create({
        model: 'gemini-3-flash-preview',
        config: {
            systemInstruction: `–°–ï–ù –é–ó–ë–ï–ö–ò–°–¢–û–ù “ö–û–ù–£–ù–ß–ò–õ–ò–ì–ò –ë–é–ô–ò–ß–ê –≠–ö–°–ü–ï–†–¢ "“ö–û–ù–£–ù –£–°–¢–£–í–û–†–ò"–°–ê–ù.`,
            tools: [{ googleSearch: {} }],
        },
    });
};

export const generateDocument = async (docType: string, caseData: Case, t: any, language: string): Promise<{ text: string, usage: UsageInfo }> => {
    try {
        const fullText = aggregateText(caseData.caseDetails, caseData.files, 50000);
        const prompt = `“≤—É–∂–∂–∞—Ç ${docType} —Ç–∞–π—ë—Ä–ª–∞. –ò—à: ${fullText}`;
        const response = await ai.models.generateContent({
            model: 'gemini-3-pro-preview',
            contents: { parts: [{ text: prompt }] },
            config: { systemInstruction: getSystemInstruction(language), temperature: 0.3 },
        });
        return {
            text: response.text,
            usage: calculateUsage(response.usageMetadata?.totalTokenCount)
        };
    } catch (error) { throw parseGeminiError(error); }
};

export const generateClientSummary = async (summary: string, t: any, language: string): Promise<{ text: string, usage: UsageInfo }> => {
    try {
        const response = await ai.models.generateContent({
            model: 'gemini-3-flash-preview',
            config: { systemInstruction: getSystemInstruction(language), temperature: 0.5 },
        });
        return {
            text: response.text || '',
            usage: calculateUsage(response.usageMetadata?.totalTokenCount)
        };
        return {
            text: response.text || '',
            usage: calculateUsage(response.usageMetadata?.totalTokenCount)
        };
    } catch (error) { throw parseGeminiError(error); }
};

export const getArticleSummary = async (code: string, t: any, language: string): Promise<{ text: string, usage: UsageInfo }> => {
    try {
        const response = await ai.models.generateContent({
            model: 'gemini-3-flash-preview',
            contents: { parts: [{ text: `${code} –º–æ–¥–¥–∞—Å–∏ –±—û–π–∏—á–∞ –é–∑–±–µ–∫–∏—Å—Ç–æ–Ω “õ–æ–Ω—É–Ω—á–∏–ª–∏–≥–∏ –∞—Å–æ—Å–∏–¥–∞ “õ–∏—Å“õ–∞ –≤–∞ —Ç—É—à—É–Ω–∞—Ä–ª–∏ —à–∞—Ä“≥ –±–µ—Ä.` }] },
            config: { systemInstruction: getSystemInstruction(language), temperature: 0.1 },
        });
        return {
            text: response.text || '',
            usage: calculateUsage(response.usageMetadata?.totalTokenCount)
        };
    } catch (error) { throw parseGeminiError(error); }
};

export const getDocumentType = async (file: CaseFile, t: any, language: string): Promise<{ documentType: string, usage: UsageInfo }> => {
    try {
        const parts: any[] = [{ text: "“≤—É–∂–∂–∞—Ç —Ç—É—Ä–∏–Ω–∏ –∞–Ω–∏“õ–ª–∞. –§–∞“õ–∞—Ç JSON: {\"documentType\": \"...\"}" }];
        if (file.content && (file.type === 'application/pdf' || file.type.startsWith('image/'))) {
            const base64 = file.content.split(',')[1];
            parts.push({ inlineData: { mimeType: file.type, data: base64 } });
        } else if (file.extractedText) {
            parts[0].text += `\n–ú–ê–¢–ù: ${file.extractedText.substring(0, 3000)}`;
        }

        const response = await ai.models.generateContent({
            model: 'gemini-3-flash-preview',
            contents: { parts },
            config: { systemInstruction: getSystemInstruction(language), responseMimeType: "application/json" },
        });
        const result = JSON.parse(response.text.trim());
        return {
            documentType: result.documentType || "–ë–æ—à“õ–∞",
            usage: calculateUsage(response.usageMetadata?.totalTokenCount)
        };
    } catch (error) { return { documentType: "–ë–æ—à“õ–∞", usage: { totalTokens: 0, cost: 0 } }; }
};


// Use Django Backend for large files
export const analyzeLargeDocumentServer = async (file: File): Promise<string> => {
    const formData = new FormData();
    formData.append('file', file);

    try {
        // In production, use env variable VITE_API_URL
        const response = await fetch('https://advokatapi.aiproduct.uz/api/analyze-pdf/', {
            method: 'POST',
            body: formData,
        });

        if (!response.ok) {
            const errData = await response.json();
            throw new Error(errData.error || `Server error: ${response.statusText}`);
        }

        const data = await response.json();
        return data.analysis || "";
    } catch (error) {
        console.error("Backend analysis failed:", error);
        throw error;
    }
};

// Fix: Add prioritizeTasks function to handle task prioritization
export const prioritizeTasks = async (tasks: string[], t: any, language: string): Promise<string[]> => {
    try {
        const prompt = `–£—à–±—É –≤–∞–∑–∏—Ñ–∞–ª–∞—Ä–Ω–∏ “≥—É“õ—É“õ–∏–π –∂–∏“≥–∞—Ç–¥–∞–Ω –º—É“≥–∏–º–ª–∏–≥–∏ –≤–∞ –∫–µ—á–∏–∫—Ç–∏—Ä–∏–± –±—û–ª–º–∞—Å–ª–∏–≥–∏–≥–∞ “õ–∞—Ä–∞–± —Ç–∞—Ä—Ç–∏–±–ª–∞. –§–∞“õ–∞—Ç —Ç–∞—Ä—Ç–∏–±–ª–∞–Ω–≥–∞–Ω –≤–∞–∑–∏—Ñ–∞–ª–∞—Ä –º–∞—Ç–Ω–∏–Ω–∏ JSON –º–∞—Å—Å–∏–≤ –∫—û—Ä–∏–Ω–∏—à–∏–¥–∞ “õ–∞–π—Ç–∞—Ä. –í–ê–ó–ò–§–ê–õ–ê–†: ${JSON.stringify(tasks)}`;
        const response = await ai.models.generateContent({
            model: 'gemini-3-flash-preview',
            contents: { parts: [{ text: prompt }] },
            config: {
                systemInstruction: getSystemInstruction(language),
                responseMimeType: "application/json",
                responseSchema: {
                    type: Type.ARRAY,
                    items: { type: Type.STRING }
                }
            },
        });
        return JSON.parse(response.text.trim());
    } catch (error) { throw parseGeminiError(error); }
};

// Fix: Add generateTimeline function to extract timeline events from case materials
export const generateTimeline = async (caseDetails: string, files: CaseFile[], t: any, language: string): Promise<TimelineEvent[]> => {
    try {
        const fullText = aggregateText(caseDetails, files, 40000);
        const prompt = `–£—à–±—É –º–∞—Ç–Ω –≤–∞ “≥—É–∂–∂–∞—Ç–ª–∞—Ä–¥–∞–Ω –º—É“≥–∏–º –≤–æ“õ–µ–∞–ª–∞—Ä –≤–∞ –º—É–¥–¥–∞—Ç–ª–∞—Ä–Ω–∏ (timeline) –∞–Ω–∏“õ–ª–∞. –°–∞–Ω–∞–ª–∞—Ä–Ω–∏ YYYY-MM-DD —Ñ–æ—Ä–º–∞—Ç–∏–¥–∞ “õ–∞–π—Ç–∞—Ä. –ú–ê–¢–ù: ${fullText}`;
        const response = await ai.models.generateContent({
            model: 'gemini-3-flash-preview',
            contents: { parts: [{ text: prompt }] },
            config: {
                systemInstruction: getSystemInstruction(language),
                responseMimeType: "application/json",
                responseSchema: {
                    type: Type.ARRAY,
                    items: {
                        type: Type.OBJECT,
                        properties: {
                            date: { type: Type.STRING },
                            description: { type: Type.STRING }
                        },
                        required: ["date", "description"]
                    }
                }
            },
        });
        return JSON.parse(response.text.trim());
    } catch (error) { throw parseGeminiError(error); }
};

// Fix: Add transcribeAudioMemo function to record and transcribe audio using Gemini
export const transcribeAudioMemo = async (duration: number, t: any, language: string): Promise<string> => {
    return new Promise(async (resolve, reject) => {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            const mediaRecorder = new MediaRecorder(stream);
            const chunks: Blob[] = [];

            mediaRecorder.ondataavailable = (e) => chunks.push(e.data);
            mediaRecorder.onstop = async () => {
                const blob = new Blob(chunks, { type: 'audio/webm' });
                const reader = new FileReader();
                reader.readAsDataURL(blob);
                reader.onloadend = async () => {
                    const base64Data = (reader.result as string).split(',')[1];
                    try {
                        const response = await ai.models.generateContent({
                            model: 'gemini-3-flash-preview',
                            contents: {
                                parts: [
                                    { inlineData: { mimeType: 'audio/webm', data: base64Data } },
                                    { text: "–£—à–±—É –∞—É–¥–∏–æ —ë–∑—É–≤–Ω–∏ –º–∞—Ç–Ω–≥–∞ —û–≥–∏—Ä (—Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è “õ–∏–ª). –§–∞“õ–∞—Ç –º–∞—Ç–Ω–Ω–∏ —û–∑–∏–Ω–∏ “õ–∞–π—Ç–∞—Ä." }
                                ]
                            },
                            config: { systemInstruction: getSystemInstruction(language) }
                        });
                        resolve(response.text.trim());
                    } catch (err) {
                        reject(parseGeminiError(err));
                    }
                };
            };

            mediaRecorder.start();
            setTimeout(() => mediaRecorder.stop(), duration * 1000);
        } catch (err) {
            reject(new Error('error_microphone_access'));
        }
    });
};

// Fix: Add getDeepDiveAnalysis function to perform detailed case analysis
export const getDeepDiveAnalysis = async (caseDetails: string, files: CaseFile[], courtType: string, courtStage: string, participants: CaseParticipant[], t: any, language: string): Promise<{ analysis: string, usage: UsageInfo }> => {
    try {
        const fullText = aggregateText(caseDetails, files, 60000);
        const participantsList = participants.map(p => `- ${p.name}: ${p.role}`).join('\n');

        const isInvestigation = courtStage === 'Tergov_raw';
        const prompt = `–°–ï–ù - –û–õ–ò–ô –°–£–î –°–£–î–¨–Ø–°–ò–°–ê–ù. –ò—à–Ω–∏ “≥–∞—Ä —Ç–æ–º–æ–Ω–ª–∞–º–∞, —Ö–æ–ª–∏—Å–æ–Ω–∞ –≤–∞ —û—Ç–∞ —á—É“õ—É—Ä —Ç–∞“≥–ª–∏–ª “õ–∏–ª.
        
        –¢–ê–õ–ê–ë–õ–ê–†:
        1. "–ü–†–û–ö–£–†–û–† –ù–ò–ì–û“≤–ò": –ê–π–±–ª–æ–≤/–î–∞—ä–≤–æ —Ç–∞—Ä–∞—Ñ–∏–Ω–∏–Ω–≥ —ç–Ω–≥ –∫—É—á–ª–∏ –∞—Ä–≥—É–º–µ–Ω—Ç–ª–∞—Ä–∏–Ω–∏ –∫–µ–ª—Ç–∏—Ä.
        2. "–ê–î–í–û–ö–ê–¢ “≤–ò–ú–û–Ø–°–ò": “≤–∏–º–æ—è —Ç–∞—Ä–∞—Ñ–∏–Ω–∏–Ω–≥ —ç–Ω–≥ –∫—É—á–ª–∏ “õ–∞—Ä—à–∏ –¥–∞–ª–∏–ª–ª–∞—Ä–∏–Ω–∏ –∫–µ–ª—Ç–∏—Ä.
        3. "“ö–û–ù–£–ù –¢–ê–†–û–ó–ò–°–ò": –é–∑–±–µ–∫–∏—Å—Ç–æ–Ω “õ–æ–Ω—É–Ω—á–∏–ª–∏–≥–∏, –ö–æ–¥–µ–∫—Å–ª–∞—Ä –≤–∞ –û–ª–∏–π –°—É–¥ –ü–ª–µ–Ω—É–º–∏ “õ–∞—Ä–æ—Ä–ª–∞—Ä–∏–≥–∞ –∞–Ω–∏“õ “≥–∞–≤–æ–ª–∞–ª–∞—Ä (–º–æ–¥–¥–∞ —Ä–∞“õ–∞–º–ª–∞—Ä–∏ –±–∏–ª–∞–Ω) –∫–µ–ª—Ç–∏—Ä.
        4. "–§–ê–ö–¢–õ–ê–† –¢–é“ö–ù–ê–®–£–í–ò": –ò—à–¥–∞–≥–∏ –¥–∞–ª–∏–ª–ª–∞—Ä —û—Ä—Ç–∞—Å–∏–¥–∞–≥–∏ –∑–∏–¥–¥–∏—è—Ç–ª–∞—Ä–Ω–∏ —Ç–æ–ø–∏–±, —É–ª–∞—Ä–Ω–∏ "QIZIL BAYROQ" üö© –¥–µ–± –±–µ–ª–≥–∏–ª–∞.
        5. "–°–¢–†–ê–¢–ï–ì–ò–ö –ô–é–õ –•–ê–†–ò–¢–ê–°–ò": –Æ—Ç–∏—à —É—á—É–Ω “õ–∞–¥–∞–º-–±–∞“õ–∞–¥–∞–º, –∞–Ω–∏“õ –≤–∞ –ª—û–Ω–¥–∞ “≥–∞—Ä–∞–∫–∞—Ç–ª–∞—Ä —Ä–µ–∂–∞—Å–∏–Ω–∏ —Ç—É–∑.

        –ú–ê–¢–ù: ${fullText}
        –ò–®–¢–ò–†–û–ö–ß–ò–õ–ê–†: ${participantsList}
        –°–£–î –¢–£–†–ò: ${courtType}
        –ë–û–°“ö–ò–ß: ${courtStage === 'Tergov_raw' ? '–¢–µ—Ä–≥–æ–≤' : '–°—É–¥'}`;

        const response = await ai.models.generateContent({
            model: 'gemini-3-pro-preview',
            contents: { parts: [{ text: prompt }] },
            config: {
                systemInstruction: getSystemInstruction(language, isInvestigation),
                temperature: 0.6,
                thinkingConfig: { thinkingBudget: 20000 }
            },
        });

        return {
            analysis: response.text,
            usage: calculateUsage(response.usageMetadata?.totalTokenCount)
        };
    } catch (error) { throw parseGeminiError(error); }
};

export const generateSimulationData = async (caseDetails: string, files: CaseFile[], courtType: string, courtStage: string, participants: CaseParticipant[], t: any, language: string): Promise<{ courtroomScenario: string, crossExaminationQuestions: CrossExaminationQuestion[], closingArgumentLead: string, closingArgumentDefender: string, usage: UsageInfo }> => {
    try {
        const fullText = aggregateText(caseDetails, files, 50000);
        const participantsList = participants.map(p => `- ${p.name}: ${p.role}`).join('\n');

        const prompt = `–°—É–¥ –∑–∞–ª–∏ —Å–∏–º—É–ª—è—Ü–∏—è—Å–∏ —è—Ä–∞—Ç–∏–Ω–≥. –ò—à —Ç—É—Ä–∏: ${courtType}. –ò—à –±–æ—Å“õ–∏—á–∏: ${courtStage}. –ú–∞“≥–∫–µ–º–∞ –º–∞—Ç–Ω–∏: ${fullText}. –ò—à—Ç–∏—Ä–æ–∫—á–∏–ª–∞—Ä: ${participantsList}`;

        const simulationSchema = {
            type: Type.OBJECT,
            properties: {
                courtroomScenario: { type: Type.STRING },
                crossExaminationQuestions: {
                    type: Type.ARRAY,
                    items: {
                        type: Type.OBJECT,
                        properties: {
                            question: { type: Type.STRING },
                            suggestedAnswer: { type: Type.STRING }
                        },
                        required: ["question", "suggestedAnswer"]
                    }
                },
                closingArgumentLead: { type: Type.STRING },
                closingArgumentDefender: { type: Type.STRING }
            },
            required: ["courtroomScenario", "crossExaminationQuestions", "closingArgumentLead", "closingArgumentDefender"]
        };

        const response = await ai.models.generateContent({
            model: 'gemini-3-pro-preview',
            contents: { parts: [{ text: prompt }] },
            config: {
                systemInstruction: `–°–ï–ù –é–ó–ë–ï–ö–ò–°–¢–û–ù “ö–û–ù–£–ù–ß–ò–õ–ò–ì–ò –ë–é–ô–ò–ß–ê –≠–ö–°–ü–ï–†–¢ "“ö–û–ù–£–ù –£–°–¢–£–í–û–†–ò"–°–ê–ù. –°—É–¥ –∑–∞–ª–∏ —Å–∏–º—É–ª—è—Ü–∏—è—Å–∏ —è—Ä–∞—Ç–∏–Ω–≥. –ñ–∞–≤–æ–±–∏–Ω–≥–∏–∑–Ω–∏ —Ñ–∞“õ–∞—Ç —û–∑–±–µ–∫ —Ç–∏–ª–∏–¥–∞ —ë–∑–∏–Ω–≥.`,
                responseMimeType: "application/json",
                responseSchema: simulationSchema,
                temperature: 0.4,
                thinkingConfig: { thinkingBudget: 15000 }
            },
        });

        const parsed = JSON.parse(response.text.trim());
        const usage = calculateUsage(response.usageMetadata?.totalTokenCount);
        return { ...parsed, usage };
    } catch (error) { throw parseGeminiError(error); }
};

export const recognizeTextFromImage = async (base64Data: string, t: any): Promise<{ text: string, usage: UsageInfo }> => {
    try {
        const response = await ai.models.generateContent({
            model: 'gemini-3-flash-preview',
            contents: {
                parts: [
                    { inlineData: { mimeType: 'image/jpeg', data: base64Data } },
                    { text: "Extract all text from this image directly. Return only the text content." }
                ]
            },
            config: {
                systemInstruction: "You are an advanced OCR engine. Extract text exactly as it appears. If there is no text, say 'No text found'.",
                temperature: 0.1
            }
        });
        return {
            text: response.text || '',
            usage: calculateUsage(response.usageMetadata?.totalTokenCount)
        };
    } catch (error) { throw parseGeminiError(error); }
};
